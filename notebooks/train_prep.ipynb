{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "super_directory = os.path.abspath('..')\n",
    "sys.path.append(super_directory)\n",
    "\n",
    "from data_setup import data_download, get_dataloaders\n",
    "from vit import ViT\n",
    "from utils import create_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device agnostic code\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "COLOR_CHANNELS = 3\n",
    "HEIGHT_WIDTH = (224, 224)              # resized to 224 in get_dataloaders function\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATCH_SIZE = (16, 16)\n",
    "NUM_PATCHES = int((HEIGHT_WIDTH[0] / PATCH_SIZE[0]) ** 2)\n",
    "\n",
    "EMBED_DIMS = 768\n",
    "NUM_ATTN_HEADS = 12\n",
    "RATIO_HIDDEN_MLP = 4\n",
    "NUM_ENC_BLOCKS = 12\n",
    "\n",
    "NUM_EPOCHS = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload data if it hasn't been downloaded\n",
    "data_path = Path('../data/')\n",
    "\n",
    "if not data_path.is_dir():\n",
    "    data_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_path = data_path / 'desserts' / 'train'\n",
    "test_path = data_path / 'desserts' / 'test'\n",
    "\n",
    "train_dataloader, test_dataloader, class_labels = get_dataloaders(train_path=train_path,\n",
    "                                                                  test_path=test_path,\n",
    "                                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=======================================================================================================================================\n",
       "Layer (type (var_name))                                 Input Shape          Output Shape         Param #              Trainable\n",
       "=======================================================================================================================================\n",
       "ViT (ViT)                                               [32, 3, 224, 224]    [32, 5]              --                   True\n",
       "├─DataEmbeddings (data_embeddings)                      [32, 3, 224, 224]    [32, 197, 768]       152,064              True\n",
       "│    └─Conv2d (conv_layer)                              [32, 3, 224, 224]    [32, 768, 14, 14]    590,592              True\n",
       "│    └─Flatten (flatten)                                [32, 768, 14, 14]    [32, 768, 196]       --                   --\n",
       "├─Sequential (encoder_blocks)                           [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    └─EncoderBlock (0)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (1)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (2)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (3)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (4)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (5)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (6)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (7)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (8)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (9)                                 [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (10)                                [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─EncoderBlock (11)                                [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "│    │    └─MultiheadAttention (multi_head_attn)        --                   [32, 197, 768]       2,362,368            True\n",
       "│    │    └─LayerNorm (layer_norm)                      [32, 197, 768]       [32, 197, 768]       (recursive)          True\n",
       "│    │    └─Sequential (mlp)                            [32, 197, 768]       [32, 197, 768]       4,722,432            True\n",
       "│    └─LayerNorm (12)                                   [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "├─Sequential (classifier)                               [32, 768]            [32, 5]              --                   True\n",
       "│    └─Linear (0)                                       [32, 768]            [32, 3072]           2,362,368            True\n",
       "│    └─Linear (1)                                       [32, 3072]           [32, 5]              15,365               True\n",
       "=======================================================================================================================================\n",
       "Total params: 88,157,957\n",
       "Trainable params: 88,157,957\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.59\n",
       "=======================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3331.52\n",
       "Params size (MB): 238.63\n",
       "Estimated Total Size (MB): 3589.42\n",
       "======================================================================================================================================="
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model and verify structure\n",
    "model_train_fs = ViT(in_channels=3,\n",
    "                     out_dims=len(class_labels),\n",
    "                     patch_size=PATCH_SIZE,\n",
    "                     num_patches=NUM_PATCHES,\n",
    "                     embed_dims=EMBED_DIMS,\n",
    "                     num_attn_heads=NUM_ATTN_HEADS,\n",
    "                     ratio_hidden_mlp=RATIO_HIDDEN_MLP,\n",
    "                     num_encoder_blocks=NUM_ENC_BLOCKS)\n",
    "\n",
    "summary(model_train_fs,\n",
    "        input_size=(32, 3, 224, 224),   # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "VisionTransformer (VisionTransformer)                        [32, 3, 224, 224]    [32, 1000]           768                  True\n",
       "├─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 768, 14, 14]    590,592              True\n",
       "├─Encoder (encoder)                                          [32, 197, 768]       [32, 197, 768]       151,296              True\n",
       "│    └─Dropout (dropout)                                     [32, 197, 768]       [32, 197, 768]       --                   --\n",
       "│    └─Sequential (layers)                                   [32, 197, 768]       [32, 197, 768]       --                   True\n",
       "│    │    └─EncoderBlock (encoder_layer_0)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_1)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_2)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_3)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_4)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_5)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_6)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_7)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_8)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_9)                   [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_10)                  [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    │    └─EncoderBlock (encoder_layer_11)                  [32, 197, 768]       [32, 197, 768]       7,087,872            True\n",
       "│    └─LayerNorm (ln)                                        [32, 197, 768]       [32, 197, 768]       1,536                True\n",
       "├─Sequential (heads)                                         [32, 768]            [32, 1000]           --                   True\n",
       "│    └─Linear (head)                                         [32, 768]            [32, 1000]           769,000              True\n",
       "============================================================================================================================================\n",
       "Total params: 86,567,656\n",
       "Trainable params: 86,567,656\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 5.54\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3330.99\n",
       "Params size (MB): 232.27\n",
       "Estimated Total Size (MB): 3582.53\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model from torchvision\n",
    "weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
    "model_finetune = torchvision.models.vit_b_16(weights=weights)\n",
    "\n",
    "summary(model_finetune,\n",
    "        input_size=(32, 3, 224, 224),   # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "VisionTransformer (VisionTransformer)                        [32, 3, 224, 224]    [32, 5]              768                  Partial\n",
       "├─Conv2d (conv_proj)                                         [32, 3, 224, 224]    [32, 768, 14, 14]    (590,592)            False\n",
       "├─Encoder (encoder)                                          [32, 197, 768]       [32, 197, 768]       151,296              False\n",
       "│    └─Dropout (dropout)                                     [32, 197, 768]       [32, 197, 768]       --                   --\n",
       "│    └─Sequential (layers)                                   [32, 197, 768]       [32, 197, 768]       --                   False\n",
       "│    │    └─EncoderBlock (encoder_layer_0)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_1)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_2)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_3)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_4)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_5)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_6)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_7)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_8)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_9)                   [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_10)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    │    └─EncoderBlock (encoder_layer_11)                  [32, 197, 768]       [32, 197, 768]       (7,087,872)          False\n",
       "│    └─LayerNorm (ln)                                        [32, 197, 768]       [32, 197, 768]       (1,536)              False\n",
       "├─Linear (heads)                                             [32, 768]            [32, 5]              3,845                True\n",
       "============================================================================================================================================\n",
       "Total params: 85,802,501\n",
       "Trainable params: 4,613\n",
       "Non-trainable params: 85,797,888\n",
       "Total mult-adds (Units.GIGABYTES): 5.52\n",
       "============================================================================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 3330.74\n",
       "Params size (MB): 229.21\n",
       "Estimated Total Size (MB): 3579.21\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_finetune.heads = torch.nn.Linear(in_features=EMBED_DIMS,\n",
    "                                       out_features=len(class_labels))\n",
    "\n",
    "for param in model_finetune.conv_proj.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "for param in model_finetune.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "summary(model_finetune,\n",
    "        input_size=(32, 3, 224, 224),   # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, optimizer, accuracy\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_train_fs.parameters(),\n",
    "                             lr = 0.01)\n",
    "\n",
    "accuracy_function = torchmetrics.Accuracy(task='multiclass', \n",
    "                                          num_classes=len(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: torch.nn.Module,\n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                loss_function: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_function: torchmetrics.Accuracy,\n",
    "                device: torch.device) -> Dict[str, float]:\n",
    "    # Model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Model to train mode\n",
    "    model = model.train()\n",
    "\n",
    "    # Track avg loss\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for X, y in train_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass -> loss -> zero grad -> back prop -> gradient descent\n",
    "        y_logits = model(X)\n",
    "        loss = loss_function(y_logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy_function = accuracy_function.to(device)\n",
    "        y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).squeeze()\n",
    "        accuracy = accuracy_function(y_preds, y)\n",
    "        \n",
    "        # Accumulate\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy\n",
    "\n",
    "    # Average per batch\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)    \n",
    "    return {'train_loss': train_loss.item(),\n",
    "            'train_acc': train_acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_results = train_epoch(model=model,\n",
    "#                             train_dataloader=train_dataloader,\n",
    "#                             loss_function=loss_function,\n",
    "#                             optimizer=optimizer,\n",
    "#                             accuracy_function=accuracy_function,\n",
    "#                             device=device)\n",
    "# print(train_results)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model: torch.nn.Module,\n",
    "               test_dataloader: torch.utils.data.DataLoader,\n",
    "               loss_function: torch.nn.Module,\n",
    "               accuracy_function: torchmetrics.Accuracy,\n",
    "               device: torch.device) -> Dict[str, float]:\n",
    "    # Model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model = model.eval()\n",
    "\n",
    "    # Track avg loss\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # With inference to save cuda memory\n",
    "        with torch.inference_mode():\n",
    "            # Loss\n",
    "            y_logits = model(X)\n",
    "            loss = loss_function(y_logits, y)\n",
    "            \n",
    "            # Accuracy\n",
    "            accuracy_function = accuracy_function.to(device)\n",
    "            y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).squeeze()\n",
    "            accuracy = accuracy_function(y_preds, y)\n",
    "            \n",
    "            # Accumulate\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy\n",
    "\n",
    "    # Average per batch\n",
    "    with torch.inference_mode():\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    return {'test_loss': test_loss.item(),\n",
    "            'test_acc': test_acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_results = test_epoch(model=model,\n",
    "#                           test_dataloader=test_dataloader,\n",
    "#                           loss_function=loss_function,\n",
    "#                           accuracy_function=accuracy_function,\n",
    "#                           device=device)\n",
    "# print(test_results)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs: int,\n",
    "          model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_function: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          accuracy_function: torchmetrics.Accuracy,\n",
    "          device: torch.device,\n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List[float]]:\n",
    "    \n",
    "      results = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'test_loss': [],\n",
    "            'test_acc': []\n",
    "      }\n",
    "    \n",
    "      for epoch in tqdm(range(num_epochs)):\n",
    "            print(\"-\"*50 + \"\\n\")\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_result = train_epoch(model=model,\n",
    "                                          train_dataloader=train_dataloader,\n",
    "                                          loss_function=loss_function,\n",
    "                                          optimizer=optimizer,\n",
    "                                          accuracy_function=accuracy_function,\n",
    "                                          device=device)\n",
    "            \n",
    "            # Do testing after one epoch\n",
    "            test_result = test_epoch(model=model,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    loss_function=loss_function,\n",
    "                                    accuracy_function=accuracy_function,\n",
    "                                    device=device)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Epoch: {epoch}  |  Train Loss: {train_result['train_loss']:.2f}  |  Test Loss: {test_result['test_loss']:.2f}  |  Train Accuracy: {train_result['train_acc']:.2f}  |  Test Accuracy: {test_result['test_acc']:.2f}\")\n",
    "            \n",
    "            # Track results\n",
    "            results['train_loss'].append(train_result['train_loss'])\n",
    "            results['train_acc'].append(train_result['train_acc'])\n",
    "            results['test_loss'].append(test_result['test_loss'])\n",
    "            results['test_acc'].append(test_result['test_acc'])\n",
    "            \n",
    "            # Using tensorboard writer for result tracking\n",
    "            writer.add_scalars(main_tag=\"Loss\",\n",
    "                               tag_scalar_dict={'train_loss': train_result['train_loss'],\n",
    "                                                'test_loss': test_result['test_loss']},\n",
    "                               global_step=epoch)\n",
    "            \n",
    "            writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                               tag_scalar_dict={'train_acc': train_result['train_acc'],\n",
    "                                                'test_acc': test_result['test_acc']},\n",
    "                               global_step=epoch)\n",
    "            \n",
    "            # Empty cuda cache for memory management\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "      writer.close()\n",
    "      \n",
    "      return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created SummaryWriter, saving to: runs/24-11-25/custom_vit/test...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f0750b982cd4958b42abfa79f1e3d2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer = create_writer(model_name='custom_vit',\n",
    "                       experiment_name='test')\n",
    "\n",
    "results = train(num_epochs=NUM_EPOCHS,\n",
    "                model=model_train_fs,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                loss_function=loss_function,\n",
    "                optimizer=optimizer,\n",
    "                accuracy_function=accuracy_function,\n",
    "                device=device,\n",
    "                writer=writer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".replicating-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
