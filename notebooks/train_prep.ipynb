{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "from torchinfo import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, List\n",
    "\n",
    "super_directory = os.path.abspath('..')\n",
    "sys.path.append(super_directory)\n",
    "\n",
    "from data_setup import data_download, get_dataloaders\n",
    "from vit import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "COLOR_CHANNELS = 3\n",
    "HEIGHT_WIDTH = (224, 224)              # resized to 224 in get_dataloaders function\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PATCH_SIZE = (16, 16)\n",
    "NUM_PATCHES = int((HEIGHT_WIDTH[0] / PATCH_SIZE[0]) ** 2)\n",
    "\n",
    "EMBED_DIMS = 768\n",
    "NUM_ATTN_HEADS = 12\n",
    "RATIO_HIDDEN_MLP = 4\n",
    "NUM_ENC_BLOCKS = 12\n",
    "\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload data if it hasn't been downloaded\n",
    "data_path = Path('../data/')\n",
    "\n",
    "if not data_path.is_dir():\n",
    "    data_download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "train_path = data_path / 'desserts' / 'train'\n",
    "test_path = data_path / 'desserts' / 'test'\n",
    "\n",
    "train_dataloader, test_dataloader, class_labels = get_dataloaders(train_path=train_path,\n",
    "                                                                  test_path=test_path,\n",
    "                                                                  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and verify structure\n",
    "model = ViT(in_channels=3,\n",
    "            out_dims=len(class_labels),\n",
    "            patch_size=PATCH_SIZE,\n",
    "            num_patches=NUM_PATCHES,\n",
    "            embed_dims=EMBED_DIMS,\n",
    "            num_attn_heads=NUM_ATTN_HEADS,\n",
    "            ratio_hidden_mlp=RATIO_HIDDEN_MLP,\n",
    "            num_encoder_blocks=NUM_ENC_BLOCKS)\n",
    "\n",
    "summary(model,\n",
    "        input_size=(32, 3, 224, 224),   # Batch dim, color channels, height, width\n",
    "        col_names=['input_size', 'output_size', 'num_params', 'trainable'],\n",
    "        col_width=20,\n",
    "        row_settings=['var_names'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, optimizer, accuracy\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                             lr = 0.01)\n",
    "\n",
    "accuracy_function = torchmetrics.Accuracy(task='multiclass', \n",
    "                                          num_classes=len(class_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model: torch.nn.Module,\n",
    "                train_dataloader: torch.utils.data.DataLoader,\n",
    "                loss_function: torch.nn.Module,\n",
    "                optimizer: torch.optim.Optimizer,\n",
    "                accuracy_function: torchmetrics.Accuracy,\n",
    "                device: torch.device) -> Dict[str, float]:\n",
    "    # Model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Model to train mode\n",
    "    model = model.train()\n",
    "\n",
    "    # Track avg loss\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for X, y in tqdm(train_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        # Forward pass -> loss -> zero grad -> back prop -> gradient descent\n",
    "        y_logits = model(X)\n",
    "        loss = loss_function(y_logits, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accuracy\n",
    "        accuracy_function = accuracy_function.to(device)\n",
    "        y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).squeeze()\n",
    "        accuracy = accuracy_function(y_preds, y)\n",
    "        \n",
    "        # Accumulate\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy\n",
    "\n",
    "    # Average per batch\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)    \n",
    "    return {'train_loss': train_loss.item(),\n",
    "            'train_acc': train_acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = train_epoch(model=model,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            loss_function=loss_function,\n",
    "                            optimizer=optimizer,\n",
    "                            accuracy_function=accuracy_function,\n",
    "                            device=device)\n",
    "print(train_results)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_epoch(model: torch.nn.Module,\n",
    "               test_dataloader: torch.utils.data.DataLoader,\n",
    "               loss_function: torch.nn.Module,\n",
    "               accuracy_function: torchmetrics.Accuracy,\n",
    "               device: torch.device) -> Dict[str, float]:\n",
    "    # Model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model = model.eval()\n",
    "\n",
    "    # Track avg loss\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    for X, y in tqdm(test_dataloader):\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        # With inference to save cuda memory\n",
    "        with torch.inference_mode():\n",
    "            # Loss\n",
    "            y_logits = model(X)\n",
    "            loss = loss_function(y_logits, y)\n",
    "            \n",
    "            # Accuracy\n",
    "            accuracy_function = accuracy_function.to(device)\n",
    "            y_preds = torch.argmax(torch.softmax(y_logits, dim=1), dim=1).squeeze()\n",
    "            accuracy = accuracy_function(y_preds, y)\n",
    "            \n",
    "            # Accumulate\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy\n",
    "\n",
    "    # Average per batch\n",
    "    with torch.inference_mode():\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "    \n",
    "    return {'test_loss': test_loss.item(),\n",
    "            'test_acc': test_acc.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = test_epoch(model=model,\n",
    "                          test_dataloader=test_dataloader,\n",
    "                          loss_function=loss_function,\n",
    "                          accuracy_function=accuracy_function,\n",
    "                          device=device)\n",
    "print(test_results)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs: int,\n",
    "          model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss_function: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          accuracy_function: torchmetrics.Accuracy,\n",
    "          device: torch.device,\n",
    "          writer: torch.utils.tensorboard.writer.SummaryWriter) -> Dict[str, List[float]]:\n",
    "    \n",
    "      results = {\n",
    "            'train_loss': [],\n",
    "            'train_acc': [],\n",
    "            'train_loss': [],\n",
    "            'test_acc': []\n",
    "      }\n",
    "    \n",
    "      for epoch in tqdm(range(num_epochs)):\n",
    "            print(\"-\"*25 + \"\\n\")\n",
    "            \n",
    "            # Train for one epoch\n",
    "            train_result = train_epoch(model=model,\n",
    "                                          train_dataloader=train_dataloader,\n",
    "                                          loss_function=loss_function,\n",
    "                                          optimizer=optimizer,\n",
    "                                          accuracy_function=accuracy_function,\n",
    "                                          device=device)\n",
    "            \n",
    "            # Do testing after one epoch\n",
    "            test_result = test_epoch(model=model,\n",
    "                                    test_dataloader=test_dataloader,\n",
    "                                    loss_function=loss_function,\n",
    "                                    accuracy_function=accuracy_function,\n",
    "                                    device=device)\n",
    "            \n",
    "            # Print results\n",
    "            print(f\"Epoch: {epoch}  |  Train Loss: {train_result['train_loss']:.2f}  |  Test Loss: {test_result['test_loss']:.2f}  |  Train Accuracy: {train_result['train_acc']:.2f}  |  Test Accuracy: {test_result['test_acc']:.2f}\")\n",
    "            \n",
    "            # Track results\n",
    "            results['train_loss'].append(train_result['train_loss'])\n",
    "            results['train_acc'].append(train_result['train_acc'])\n",
    "            results['test_loss'].append(test_result['test_loss'])\n",
    "            results['test_acc'].append(test_result['test_acc'])\n",
    "            \n",
    "            # Using tensorboard writer for result tracking\n",
    "            writer.add_scalars(main_tag=\"Loss\",\n",
    "                               tag_scalar_dict={'train_loss': train_result['train_loss'],\n",
    "                                                'test_loss': test_result['test_loss']},\n",
    "                               global_step=epoch)\n",
    "            \n",
    "            writer.add_scalars(main_tag=\"Accuracy\",\n",
    "                               tag_scalar_dict={'train_acc': train_result['train_acc'],\n",
    "                                                'test_acc': test_result['test_acc']},\n",
    "                               global_step=epoch)\n",
    "            \n",
    "            # Empty cuda cache for memory management\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "      writer.close()\n",
    "      \n",
    "      return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".replicating-vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
